# -*- coding: utf-8 -*-
"""Stocks_Predictions_AAPL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jSHDg9njz05YmHZq3hrFSSCuXQk5AaPJ

# Problem Statement:
Stock Price Prediction for Apple Inc. using Historical Data


---


**Objective:**

---


TStock price prediction is a complex and challenging task due to the dynamic nature of financial markets, which are influenced by multiple factors such as market trends, investor sentiment, and global economic conditions. Traditional models often struggle to capture the intricate dependencies in stock price movements.

This project aims to develop a deep learning-based prediction model using Stacked Long Short-Term Memory (LSTM) networks to forecast Apple Inc. (AAPL) stock prices. The objective is to predict stock prices based on historical data, helping traders and investors make informed decisions.

# Project Description


---


This project leverages historical stock price data to train a Stacked LSTM model, a deep learning approach that excels in time-series forecasting. The workflow consists of the following key steps:
---

1Ô∏è‚É£ Data Collection:


---



Historical stock data for Apple Inc. (AAPL) is retrieved from the Tiingo API.

The dataset includes features such as Open, High, Low, Close, Adjusted Close, and Volume, spanning from 2022 to 2025.

2Ô∏è‚É£ Data Preprocessing:


---



The data is formatted into a Pandas DataFrame and checked for missing values.

The Close Price is selected as the primary target variable for forecasting.

The dataset is normalized using MinMaxScaler to improve model convergence.

A sliding window technique is applied to create time-series sequences.

3Ô∏è‚É£ Feature Engineering:


---



The model uses past 60 days of stock prices to predict the next day‚Äôs price.

Data is split into training and testing sets for model evaluation.

4Ô∏è‚É£ Model Development ‚Äì Stacked LSTM:


---



A deep learning model with multiple stacked LSTM layers is implemented using TensorFlow/Keras.

The architecture includes:

Three stacked LSTM layers to capture long-term dependencies in stock prices.

Dropout layers to prevent overfitting.

A Dense output layer to generate stock price predictions.

The model is compiled with:

Adam optimizer for efficient learning.

Mean Squared Error (MSE) loss function to minimize prediction errors.

5Ô∏è‚É£ Model Training & Evaluation:


---



The model is trained using historical data and evaluated using:

Root Mean Squared Error (RMSE)

Mean Absolute Error (MAE)

Directional Accuracy (percentage of correct price movement predictions)

The predicted stock prices are compared with actual prices using visualizations.

6Ô∏è‚É£ Future Stock Price Prediction:


---



The trained model is used to predict AAPL stock prices for:

Next Day (1-day ahead forecast)

Next 7 Days (week-ahead forecast)

Next 30 Days (month-ahead forecast)

The predicted trends are visualized using Matplotlib and Seaborn.

#Install all necessary packages
"""

!pip install --upgrade pandas_datareader yfinance requests

!pip install --upgrade pandas_datareader

"""#Set up the key from Tiingo"""

import pandas as pd
import requests

key = "68767a948667a6bb06594061cdbfcf51a580e5e4"
url = f"https://api.tiingo.com/tiingo/daily/AAPL/prices?startDate=2022-01-01&endDate=2025-01-01&token={key}"

"""# Fetching the data"""

response = requests.get(url)
data = response.json()

# Check the number of rows received
print(f"Number of rows fetched: {len(data)}")

"""# Convert to DataFrame"""

df = pd.DataFrame(data)

"""#Save the dataset"""

df.to_csv('AAPL.csv')

import pandas as pd

"""#Read the dataset"""

df=pd.read_csv('AAPL.csv')

"""#Head of the dataset (First 5 rows)"""

df.head()

"""#Last 5 rows of dataset"""

df.tail()

"""#Visual representation of stock price with respect to date"""

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(df["date"], df["close"], marker='o', linestyle='-')
plt.xlabel("Date")
plt.ylabel("Stock Price (USD)")
plt.title("AAPL Stock Price Over Time")
plt.grid()
plt.show()

""" #Extract only the closing prices as a simple sequence (Series).

 It is useful when performing time-series forecasting
"""

df1=df.reset_index()['close']

df1

import matplotlib.pyplot as plt
plt.plot(df1)

import numpy as np

df1

"""### LSTM are sensitive to the scale of the data. so we apply MinMax scaler"""

from sklearn.preprocessing import MinMaxScaler
scaler=MinMaxScaler(feature_range=(0,1))
df1=scaler.fit_transform(np.array(df1).reshape(-1,1))

print(df1)

"""##splitting dataset into train and test split"""

training_size=int(len(df1)*0.65)
test_size=len(df1)-training_size
train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]

training_size,test_size

train_data

"""
# convert an array of values into a dataset matrix"""

import numpy
def create_dataset(dataset, time_step=1):
	dataX, dataY = [], []
	for i in range(len(dataset)-time_step-1):
		a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100
		dataX.append(a)
		dataY.append(dataset[i + time_step, 0])
	return numpy.array(dataX), numpy.array(dataY)

"""# reshape into X=t,t+1,t+2,t+3 and Y=t+4"""

time_step = 100
X_train, y_train = create_dataset(train_data, time_step)
X_test, ytest = create_dataset(test_data, time_step)

print(X_train.shape), print(y_train.shape)

print(X_test.shape), print(ytest.shape)

"""# reshape input to be [samples, time steps, features] which is required for LSTM"""

X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)
X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)

"""### Create the Stacked LSTM model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM

model=Sequential()
model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))
model.add(LSTM(50,return_sequences=True))
model.add(LSTM(50))
model.add(Dense(1))
model.compile(loss='mean_squared_error',optimizer='adam')

model.summary()

model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)

import tensorflow as tf

"""### Lets Do the prediction and check performance metrics"""

train_predict=model.predict(X_train)
test_predict=model.predict(X_test)

"""##Transformback to original form"""

train_predict=scaler.inverse_transform(train_predict)
test_predict=scaler.inverse_transform(test_predict)

"""### Calculate RMSE performance metrics"""

import math
from sklearn.metrics import mean_squared_error
math.sqrt(mean_squared_error(y_train,train_predict))

"""### Test Data RMSE"""

math.sqrt(mean_squared_error(ytest,test_predict))

"""### Plotting"""

# shift train predictions for plotting
look_back=100
trainPredictPlot = numpy.empty_like(df1)
trainPredictPlot[:, :] = np.nan
trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict
# shift test predictions for plotting
testPredictPlot = numpy.empty_like(df1)
testPredictPlot[:, :] = numpy.nan
testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict
# plot baseline and predictions
plt.plot(scaler.inverse_transform(df1))
plt.plot(trainPredictPlot)
plt.plot(testPredictPlot)
plt.show()

len(test_data)

"""#Giving inputs to model for predictions"""

x_input=test_data[164:].reshape(1,-1)
x_input.shape

temp_input=list(x_input)
temp_input=temp_input[0].tolist()

temp_input

"""# demonstrate prediction for next 10 days"""

from numpy import array

lst_output=[]
n_steps=100
i=0
while(i<30):

    if(len(temp_input)>100):
        #print(temp_input)
        x_input=np.array(temp_input[1:])
        print("{} day input {}".format(i,x_input))
        x_input=x_input.reshape(1,-1)
        x_input = x_input.reshape((1, n_steps, 1))
        #print(x_input)
        yhat = model.predict(x_input, verbose=0)
        print("{} day output {}".format(i,yhat))
        temp_input.extend(yhat[0].tolist())
        temp_input=temp_input[1:]
        #print(temp_input)
        lst_output.extend(yhat.tolist())
        i=i+1
    else:
        x_input = x_input.reshape((1, n_steps,1))
        yhat = model.predict(x_input, verbose=0)
        print(yhat[0])
        temp_input.extend(yhat[0].tolist())
        print(len(temp_input))
        lst_output.extend(yhat.tolist())
        i=i+1


print(lst_output)

"""##More future predictions"""

day_new=np.arange(1,101)
day_pred=np.arange(101,131)

import matplotlib.pyplot as plt

len(df1)

"""#plot of available data and new predictions"""

plt.plot(day_new,scaler.inverse_transform(df1[653:]))
plt.plot(day_pred,scaler.inverse_transform(lst_output))

"""#combination of actual data that extended with predicted result (Predictions)"""

df3=df1.tolist()
df3.extend(lst_output)
plt.plot(df3[700:])

df3=scaler.inverse_transform(df3).tolist()

"""#Actual data"""

plt.plot(df3)

"""# Key Observations
‚úÖ The Stacked LSTM model captures short-term stock price trends effectively.

‚úÖ The training loss decreases, indicating that the model is learning well.

‚úÖ Short-term predictions (1-day and 7-day forecasts) align well with actual stock prices.

‚úÖ Long-term predictions (30-day forecast) exhibit higher deviations due to market volatility.

‚úÖ The model struggles with sharp trend reversals, suggesting a need for additional feature engineering.

# üìå Conclusion:

The Stacked LSTM model successfully predicts AAPL stock prices with reasonable accuracy in the short term.

The model provides valuable insights but has limitations in long-term forecasting due to stock market volatility.
"""

